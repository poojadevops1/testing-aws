<!---
This is an autogenerated file!

Please do not edit this file directly, but instead make changes to the
sigs.yaml file in the project root.

To understand how this file is generated, see https://git.k8s.io/community/generator/README.md
--->
# Machine Learning Working Group

Identify and fix gaps in Kubernetes to better support Machine Learning applications

## Stakeholder SIGs
* SIG Apps
* SIG Node

## Meetings
* Regular WG Meeting: [Thursdays at 17:00 PT (Pacific Time)](https://zoom.us/j/103404077) (biweekly). [Convert to your timezone](http://www.thetimezoneconverter.com/?t=17:00&tz=PT%20%28Pacific%20Time%29).
  * [Meeting notes and Agenda](https://goo.gl/gBCdt1).

## Organizers

* Klaus Ma (**[@k82cn](https://github.com/k82cn)**), Huawei
* Kenneth Owens (**[@kow3ns](https://github.com/kow3ns)**), Google
* Vishnu Kannan (**[@vishh](https://github.com/vishh)**), Google

## Contact
- Slack: [#wg-machine-learning](https://kubernetes.slack.com/messages/wg-machine-learning)
- [Mailing list](https://groups.google.com/forum/#!forum/kubernetes-wg-machine-learning)
- [Open Community Issues/PRs](https://github.com/kubernetes/community/labels/wg%2Fmachine-learning)
<!-- BEGIN CUSTOM CONTENT -->
A working group dedicated towards making Kubernetes work best for Machine Learning workloads.

The charter for this working group as [proposed](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/kubernetes-dev/lOeMjOLilxI/wuQayFDvCQAJ) is as follows:

 -  Assess the state of the art for ML workloads on K8s
 -  Identify pain points users currently have with ML on k8s
 -  Identify, prioritize and execute on improving k8s to better support ML workloads in the near, medium, and long term.

## Goals:

Topics include, but are not limited to:

 - Ease source changes to execution workflows, as they are a common barrier to entry.
 - Scheduler enhancements such as improved bin packing for accelerators, job queueing, fair sharing and gang scheduling.
 - Runtime enhancements such as job data loading (common data set sizes in the tens of gigabytes to terabytes), accelerator support, persisting job output (ML workloads can run for days and rely heavily on checkpointing) and multi-tenancy and job isolation (dealing with potential sensitive data sets).
 - Job management such as experiment tracking (including enabling hyperparameter tuning systems) and scaling and deployment aspects of inference workloads.

<!-- END CUSTOM CONTENT -->
